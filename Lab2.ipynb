{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finde_files(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    return files\n",
    "\n",
    "def delete_files(pattern):\n",
    "    files = finde_files(pattern)\n",
    "    for file in files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VHI 1 is downloaded...\n",
      "VHI 1 is modified\n",
      "VHI 2 is downloaded...\n",
      "VHI 2 is modified\n",
      "VHI 3 is downloaded...\n",
      "VHI 3 is modified\n",
      "VHI 4 is downloaded...\n",
      "VHI 4 is modified\n",
      "VHI 5 is downloaded...\n",
      "VHI 5 is modified\n",
      "VHI 6 is downloaded...\n",
      "VHI 6 is modified\n",
      "VHI 7 is downloaded...\n",
      "VHI 7 is modified\n",
      "VHI 8 is downloaded...\n",
      "VHI 8 is modified\n",
      "VHI 9 is downloaded...\n",
      "VHI 9 is modified\n",
      "VHI 10 is downloaded...\n",
      "VHI 10 is modified\n",
      "VHI 11 is downloaded...\n",
      "VHI 11 is modified\n",
      "VHI 12 is downloaded...\n",
      "VHI 12 is modified\n",
      "VHI 13 is downloaded...\n",
      "VHI 13 is modified\n",
      "VHI 14 is downloaded...\n",
      "VHI 14 is modified\n",
      "VHI 15 is downloaded...\n",
      "VHI 15 is modified\n",
      "VHI 16 is downloaded...\n",
      "VHI 16 is modified\n",
      "VHI 17 is downloaded...\n",
      "VHI 17 is modified\n",
      "VHI 18 is downloaded...\n",
      "VHI 18 is modified\n",
      "VHI 19 is downloaded...\n",
      "VHI 19 is modified\n",
      "VHI 20 is downloaded...\n",
      "VHI 20 is modified\n",
      "VHI 21 is downloaded...\n",
      "VHI 21 is modified\n",
      "VHI 22 is downloaded...\n",
      "VHI 22 is modified\n",
      "VHI 23 is downloaded...\n",
      "VHI 23 is modified\n",
      "VHI 24 is downloaded...\n",
      "VHI 24 is modified\n",
      "VHI 25 is downloaded...\n",
      "VHI 25 is modified\n",
      "VHI 26 is downloaded...\n",
      "VHI 26 is modified\n",
      "VHI 27 is downloaded...\n",
      "VHI 27 is modified\n"
     ]
    }
   ],
   "source": [
    "def install_files(path):\n",
    "    for i in range(1, 28):\n",
    "        file_pattern = f\"{path}/vhi_id_{i}_*\"\n",
    "        delete_files(file_pattern)\n",
    "        url=f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={i}&year1=1981&year2=2024&type=Mean\"\n",
    "        vhi_url = urllib.request.urlopen(url)\n",
    "        time = datetime.now()\n",
    "        now = time.strftime(\"%d_%m_%Y_%H;%M;%S\")\n",
    "        out = open(f'{path}/vhi_id_{i}_downloaded_time{now}.csv','wb')\n",
    "        out.write(vhi_url.read()) \n",
    "        out.close()\n",
    "        print(f\"VHI {i} is downloaded...\")\n",
    "\n",
    "        file_pattern = f\"{path}/vhi_id_{i}_*\"\n",
    "        file_path = finde_files(file_pattern)[0]\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "        soup = BeautifulSoup(file_content, 'html.parser')\n",
    "        cleaned_text = soup.get_text()\n",
    "        with open(file_path, 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.write(cleaned_text)\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            lines = [line.rstrip(',\\n') for line in file]\n",
    "        with open(file_path, 'w', encoding='utf-8') as temp_file:\n",
    "            temp_file.write('\\n'.join(lines))\n",
    "\n",
    "        data = pd.read_csv(file_path, lineterminator ='\\n', skiprows=1)\n",
    "        data.columns = [col.replace('\\r', '') for col in data.columns]\n",
    "        data.columns = [col.replace(' ', '') for col in data.columns]\n",
    "\n",
    "        new_indexes = {\n",
    "            1: 24, 2: 26, 3: 25, 4: 27, 5: 3, 6: 4, 7: 8, 8: 21, 9: 22,\n",
    "            10: 23, 11: 10, 12: 9, 13: 11, 14: 12, 15: 13, 16: 14, 17: 15, 18: 16,\n",
    "            19: 17, 20: 18, 21: 19, 22: 20, 23: 6, 24: 1, 25: 2, 26: 7, 27: 5,\n",
    "        }\n",
    "\n",
    "        data['area'] = new_indexes[i]\n",
    "        data = data.drop(data.loc[data['VHI'] == -1].index)\n",
    "\n",
    "        area_index = {\n",
    "            1: 'Vinnytsya', 2: 'Volyn', 3: \"Dnipropetrovs'k\", 4: \"Donets'k\", 5: 'Zhytomyr', 6: 'Transcarpathia', 7: 'Zaporizhzhya', 8: \"Ivano-Frankivs'k\", 9: 'Kiev City',\n",
    "            10: 'Kiev', 11: 'Kirovohrad', 12: \"Luhans'k\", 13: \"L'viv\", 14: 'Mykolayiv', 15: 'Odessa', 16: 'Poltava', 17: 'Rivne', 18: \"Sevastopol'\",\n",
    "            19: 'Sumy', 20: \"Ternopil'\", 21: 'Kharkiv', 22: 'Kherson', 23: \"Khmel'nyts'kyy\", 24: 'Cherkasy', 25: 'Chernivtsi', 26: 'Chernihiv', 27: 'Crimea',\n",
    "        }\n",
    "        data['area'] = data['area'].replace(area_index)\n",
    "\n",
    "        file_pattern = f\"{path}/mod_vhi_id_{new_indexes[i]}_*\"\n",
    "        delete_files(file_pattern)\n",
    "        data.to_csv(f'{path}/mod_vhi_id_{new_indexes[i]}_downloaded_time{now}.csv', index=False, encoding='utf-8')\n",
    "        print(f'VHI {i} is modified')\n",
    "\n",
    "    data_frames = []\n",
    "    for i in range(1, 28):\n",
    "        file_pattern = f\"{path}/mod_vhi_id_{i}_*\"\n",
    "        file_path = finde_files(file_pattern)[0]\n",
    "        data = pd.read_csv(file_path)\n",
    "        data_frames.append(data)\n",
    "        \n",
    "    data = pd.concat(data_frames)\n",
    "    delete_files(f'{path}/vhi_end.csv')\n",
    "    data.to_csv(f'{path}/vhi_end.csv', index=False, encoding='utf-8')\n",
    "\n",
    "install_files(\"./Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43304    44.88\n",
      "43305    46.97\n",
      "43306    49.07\n",
      "43307    48.21\n",
      "43308    45.25\n",
      "43309    41.92\n",
      "43310    39.24\n",
      "43311    39.97\n",
      "43312    41.74\n",
      "43313    42.32\n",
      "43314    41.01\n",
      "43315    42.47\n",
      "43316    43.16\n",
      "43317    42.09\n",
      "43318    41.62\n",
      "43319    43.11\n",
      "43320    48.01\n",
      "43321    52.06\n",
      "43322    54.65\n",
      "43323    56.82\n",
      "43324    58.47\n",
      "43325    61.03\n",
      "43326    62.01\n",
      "43327    61.80\n",
      "43328    63.25\n",
      "43329    63.54\n",
      "43330    61.62\n",
      "43331    61.87\n",
      "43332    62.15\n",
      "43333    61.61\n",
      "43334    61.06\n",
      "43335    60.50\n",
      "43336    60.75\n",
      "43337    62.09\n",
      "43338    62.17\n",
      "43339    61.14\n",
      "43340    60.83\n",
      "43341    59.52\n",
      "43342    57.40\n",
      "43343    57.05\n",
      "43344    56.00\n",
      "43345    53.39\n",
      "43346    50.79\n",
      "43347    47.95\n",
      "43348    48.01\n",
      "43349    45.75\n",
      "43350    45.48\n",
      "43351    48.07\n",
      "43352    52.02\n",
      "43353    51.70\n",
      "43354    51.04\n",
      "43355    52.03\n",
      "Name: VHI, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def vhi(region, year, path):\n",
    "    data = pd.read_csv(f'{path}/vhi_end.csv')\n",
    "    VHIs = data[(data[\"area\"] == region) & (data[\"year\"] == year)]['VHI']\n",
    "    delete_files(f'{path}/vhi_{region}_{year}.csv')\n",
    "    VHIs.to_csv(f'{path}/vhi_{region}_{year}.csv', index=False, encoding='utf-8')\n",
    "    return VHIs\n",
    "\n",
    "data = vhi(\"Ternopil'\", 2017, './Data')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мінімальне VHI: 30.43\n",
      "Максимальне VHI: 70.41\n",
      "Середнє VHI: 45.79\n",
      "Медіана VHI: 43.555\n"
     ]
    }
   ],
   "source": [
    "def data_filter(regions, years, path):\n",
    "    data = pd.read_csv(f'{path}/vhi_end.csv')\n",
    "    filtered_data = data[(data['area'].isin(regions)) & (data['year'].isin(years))]\n",
    "    delete_files(f'{path}/vhi_{regions}_{years}.csv')\n",
    "    filtered_data.to_csv(f'{path}/vhi_{regions}_{years}.csv', index=False, encoding='utf-8')\n",
    "    return filtered_data\n",
    "\n",
    "def minmax(regions, years, path):\n",
    "    data = data_filter(regions, years, path)\n",
    "    min_v = data['VHI'].min()\n",
    "    max_v = data['VHI'].max()\n",
    "    avrg = data['VHI'].mean()\n",
    "    mediana = data['VHI'].median()\n",
    "    return min_v, max_v, round(avrg, 2), mediana\n",
    "\n",
    "minimum, maximum, avrg, mediana = minmax(['Poltava', 'Kiev'], [2014, 2015], './Data')\n",
    "print(f\"Мінімальне VHI: {minimum}\")\n",
    "print(f\"Максимальне VHI: {maximum}\")\n",
    "print(f\"Середнє VHI: {avrg}\")\n",
    "print(f\"Медіана VHI: {mediana}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21132    42.93\n",
      "21133    39.83\n",
      "21134    38.09\n",
      "21135    38.22\n",
      "21136    38.62\n",
      "         ...  \n",
      "34451    39.78\n",
      "34452    42.71\n",
      "34453    42.94\n",
      "34454    43.81\n",
      "34455    45.99\n",
      "Name: VHI, Length: 416, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def vhi_years(fromy, toy, regions, path):\n",
    "    years = list(range(fromy, toy+1))\n",
    "    data = data_filter(regions, years, path)\n",
    "    return data['VHI']\n",
    "\n",
    "vhi = vhi_years(2011, 2014, ['Poltava', 'Kiev'], './Data')\n",
    "print(vhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year         area    VHI\n",
      "950    2000    Vinnytsya  12.26\n",
      "18435  2000    Kiev City  14.89\n",
      "20623  2000         Kiev  12.51\n",
      "38112  2000  Sevastopol'  13.14\n",
      "44671  2000      Kharkiv  14.61\n",
      "51227  2000     Cherkasy  14.64\n"
     ]
    }
   ],
   "source": [
    "def finde_extreme_drought(percent, path):\n",
    "    data = pd.read_csv(f'{path}/vhi_end.csv')\n",
    "    total_of_area = data['area'].nunique()\n",
    "    df_drought = data[(data.VHI <= 15)]\n",
    "    df_drought = df_drought.drop_duplicates(subset=['year', 'area'])\n",
    "    drought_counts = df_drought.groupby('year')['area'].nunique().reset_index()\n",
    "    extreme_drought = drought_counts[drought_counts['area'] > (total_of_area / 100 * percent)]['year']\n",
    "    extreme_drought_data = df_drought[df_drought['year'].isin(extreme_drought)]\n",
    "    extreme_drought_data = extreme_drought_data.sort_values(by='year')\n",
    "    print(extreme_drought_data[['year', 'area', 'VHI']])\n",
    "    delete_files(f'{path}/vhi_extreme_drought.csv')\n",
    "    extreme_drought_data.to_csv(f'{path}/vhi_extreme_drought.csv', index=False, encoding='utf-8')\n",
    "\n",
    "finde_extreme_drought(20, './Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
