{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finde_files(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    return files\n",
    "\n",
    "def delete_files(pattern):\n",
    "    files = finde_files(pattern)\n",
    "    for file in files:\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VHI 1 is downloaded...\n",
      "VHI 2 is downloaded...\n",
      "VHI 3 is downloaded...\n",
      "VHI 4 is downloaded...\n",
      "VHI 5 is downloaded...\n",
      "VHI 6 is downloaded...\n",
      "VHI 7 is downloaded...\n",
      "VHI 8 is downloaded...\n",
      "VHI 9 is downloaded...\n",
      "VHI 10 is downloaded...\n",
      "VHI 11 is downloaded...\n",
      "VHI 12 is downloaded...\n",
      "VHI 13 is downloaded...\n",
      "VHI 14 is downloaded...\n",
      "VHI 15 is downloaded...\n",
      "VHI 16 is downloaded...\n",
      "VHI 17 is downloaded...\n",
      "VHI 18 is downloaded...\n",
      "VHI 19 is downloaded...\n",
      "VHI 20 is downloaded...\n",
      "VHI 21 is downloaded...\n",
      "VHI 22 is downloaded...\n",
      "VHI 23 is downloaded...\n",
      "VHI 24 is downloaded...\n",
      "VHI 25 is downloaded...\n",
      "VHI 26 is downloaded...\n",
      "VHI 27 is downloaded...\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 28):\n",
    "    file_pattern = f\"vhi_id_{i}_*\"\n",
    "    delete_files(file_pattern)\n",
    "    url=f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={i}&year1=1981&year2=2024&type=Mean\"\n",
    "    vhi_url = urllib.request.urlopen(url)\n",
    "    time = datetime.now()\n",
    "    now = time.strftime(\"%d_%m_%Y_%H;%M;%S\")\n",
    "    out = open(f'vhi_id_{i}_downloaded_time{now}.csv','wb')\n",
    "    out.write(vhi_url.read()) \n",
    "    out.close()\n",
    "    print(f\"VHI {i} is downloaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 28):\n",
    "    file_pattern = f\"vhi_id_{i}_*\"\n",
    "    file_path = finde_files(file_pattern)[0]\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "    soup = BeautifulSoup(file_content, 'html.parser')\n",
    "    cleaned_text = soup.get_text()\n",
    "    with open(file_path, 'w', encoding='utf-8') as temp_file:\n",
    "        temp_file.write(cleaned_text)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = [line.rstrip(',\\n') for line in file]\n",
    "    with open(file_path, 'w', encoding='utf-8') as temp_file:\n",
    "        temp_file.write('\\n'.join(lines))\n",
    "\n",
    "    data = pd.read_csv(file_path, lineterminator ='\\n', skiprows=1)\n",
    "    data.columns = [col.replace('\\r', '') for col in data.columns]\n",
    "    data.columns = [col.replace(' ', '') for col in data.columns]\n",
    "    data['area'] = i\n",
    "    data = data.drop(data.loc[data['VHI'] == -1].index)\n",
    "    delete_files(file_pattern)\n",
    "    data.to_csv(file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 28):\n",
    "    file_pattern = f\"vhi_id_{i}_*\"\n",
    "    file_path = finde_files(file_pattern)[0]\n",
    "    data = pd.read_csv(file_path)\n",
    "    area_index = {\n",
    "        1: 'Vinnytsya', 2: 'Volyn', 3: \"Dnipropetrovs'k\", 4: \"Donets'k\", 5: 'Zhytomyr', 6: 'Transcarpathia', 7: 'Zaporizhzhya', 8: \"Ivano-Frankivs'k\", 9: 'Kiev City',\n",
    "        10: 'Kiev', 11: 'Kirovohrad', 12: \"Luhans'k\", 13: \"L'viv\", 14: 'Mykolayiv', 15: 'Odessa', 16: 'Poltava', 17: 'Rivne', 18: \"Sevastopol'\",\n",
    "        19: 'Sumy', 20: \"Ternopil'\", 21: 'Kharkiv', 22: 'Kherson', 23: \"Khmel'nyts'kyy\", 24: 'Cherkasy', 25: 'Chernivtsi', 26: 'Chernihiv', 27: 'Crimea',\n",
    "    }\n",
    "    data['area'] = data['area'].replace(area_index)\n",
    "    data.to_csv(f'mod_{file_path}', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for i in range(1, 28):\n",
    "    file_pattern = f\"mod_vhi_id_{i}_*\"\n",
    "    file_path = finde_files(file_pattern)[0]\n",
    "    data = pd.read_csv(file_path)\n",
    "    data_frames.append(data)\n",
    "    \n",
    "data = pd.concat(data_frames)\n",
    "\n",
    "data.to_csv('vhi_end.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43304    54.10\n",
      "43305    53.72\n",
      "43306    52.13\n",
      "43307    49.95\n",
      "43308    50.07\n",
      "43309    48.82\n",
      "43310    47.34\n",
      "43311    46.10\n",
      "43312    45.34\n",
      "43313    44.11\n",
      "43314    42.67\n",
      "43315    43.09\n",
      "43316    44.58\n",
      "43317    45.97\n",
      "43318    47.94\n",
      "43319    50.14\n",
      "43320    56.26\n",
      "43321    62.28\n",
      "43322    64.26\n",
      "43323    67.14\n",
      "43324    67.63\n",
      "43325    68.67\n",
      "43326    68.37\n",
      "43327    66.86\n",
      "43328    66.32\n",
      "43329    66.09\n",
      "43330    64.63\n",
      "43331    63.37\n",
      "43332    62.34\n",
      "43333    60.25\n",
      "43334    59.06\n",
      "43335    59.11\n",
      "43336    58.67\n",
      "43337    57.50\n",
      "43338    53.19\n",
      "43339    49.54\n",
      "43340    48.21\n",
      "43341    47.39\n",
      "43342    48.85\n",
      "43343    50.30\n",
      "43344    52.69\n",
      "43345    53.94\n",
      "43346    51.98\n",
      "43347    46.19\n",
      "43348    46.21\n",
      "43349    42.56\n",
      "43350    39.65\n",
      "43351    37.05\n",
      "43352    36.24\n",
      "43353    36.14\n",
      "43354    38.05\n",
      "43355    41.78\n",
      "Name: VHI, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def vhi(region, year):\n",
    "    data = pd.read_csv('vhi_end.csv')\n",
    "    VHIs = data[(data[\"area\"] == region) & (data[\"year\"] == year)]['VHI']\n",
    "    VHIs.to_csv('vhi_row.csv', index=False, encoding='utf-8')\n",
    "    return VHIs\n",
    "\n",
    "data = vhi(\"Ternopil'\", 2017)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мінімальне VHI: 19.95\n",
      "Максимальне VHI: 64.33\n",
      "Середнє VHI: 43.3\n",
      "Медіана VHI: 42.685\n"
     ]
    }
   ],
   "source": [
    "def data_filter(regions, years):\n",
    "    data = pd.read_csv('vhi_end.csv')\n",
    "    filtered_data = data[(data['area'].isin(regions)) & (data['year'].isin(years))]\n",
    "    filtered_data.to_csv('vhi_row.csv', index=False, encoding='utf-8')\n",
    "    return filtered_data\n",
    "\n",
    "def minmax(regions, years):\n",
    "    data = data_filter(regions, years)\n",
    "    min_v = data['VHI'].min()\n",
    "    max_v = data['VHI'].max()\n",
    "    avrg = data['VHI'].mean()\n",
    "    mediana = data['VHI'].median()\n",
    "    return min_v, max_v, round(avrg, 2), mediana\n",
    "\n",
    "minimum, maximum, avrg, mediana = minmax(['Poltava', 'Kiev'], [2014, 2015])\n",
    "print(f\"Мінімальне VHI: {minimum}\")\n",
    "print(f\"Максимальне VHI: {maximum}\")\n",
    "print(f\"Середнє VHI: {avrg}\")\n",
    "print(f\"Медіана VHI: {mediana}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21132    42.00\n",
      "21133    39.82\n",
      "21134    38.35\n",
      "21135    36.72\n",
      "21136    35.69\n",
      "         ...  \n",
      "34451    37.26\n",
      "34452    38.34\n",
      "34453    37.71\n",
      "34454    37.71\n",
      "34455    38.44\n",
      "Name: VHI, Length: 416, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def vhi_years(fromy, toy, regions):\n",
    "    data = pd.read_csv('vhi_end.csv')\n",
    "    years = list(range(fromy, toy+1))\n",
    "    vhi = data[(data['area'].isin(regions)) & (data['year'].isin(years))]\n",
    "    vhi.to_csv('vhi_row.csv', index=False, encoding='utf-8')\n",
    "    return vhi['VHI']\n",
    "\n",
    "vhi = vhi_years(2011, 2014, ['Poltava', 'Kiev'])\n",
    "print(vhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year              area    VHI\n",
      "949    2000         Vinnytsya  14.64\n",
      "16253  2000  Ivano-Frankivs'k  14.61\n",
      "22809  2000        Kirovohrad  12.51\n",
      "24993  2000          Luhans'k  14.89\n",
      "42484  2000         Ternopil'  13.14\n",
      "51228  2000          Cherkasy  12.26\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('vhi_end.csv')\n",
    "df_drought = data[(data.VHI <= 15)]\n",
    "df_drought = df_drought.drop_duplicates(subset=['year', 'area'])\n",
    "drought_counts = df_drought.groupby('year')['area'].nunique().reset_index()\n",
    "extreme_drought = drought_counts[drought_counts['area'] > 5]['year']\n",
    "extreme_drought_data = df_drought[df_drought['year'].isin(extreme_drought)]\n",
    "print(extreme_drought_data[['year', 'area', 'VHI']])\n",
    "extreme_drought_data.to_csv('vhi_rowssss.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
